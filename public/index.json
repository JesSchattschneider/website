[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a data analyst, with a focus on using open source tools. Having an academic background in oceanography and geoprocessing, I have a passion to use geospatial tools to better understand the complexity of marine and coastal environments. My interests are also in integrating and tidying multiple datasets into structured databases and in automate common processes to improve and analyse spatial and temporal trends.\nI have a mix of experience working for governamental organizations, NGO\u0026rsquo;s and academia, for more details, please have a look on my full CV or check some of my past and ongoing projects. On posts I share how I implemented some pieces of my work.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/jessica-leiria-schattschneider/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jessica-leiria-schattschneider/","section":"authors","summary":"I\u0026rsquo;m a data analyst, with a focus on using open source tools. Having an academic background in oceanography and geoprocessing, I have a passion to use geospatial tools to better understand the complexity of marine and coastal environments.","tags":null,"title":"Jessica Leiria Schattschneider","type":"authors"},{"authors":null,"categories":["R"],"content":"        Motivation Data available: Code structure: Starting to code Part 01 - Create a function Part 02 - Create 20 coastal sectors Part 03 - Fix geometries intersection and calculate the monitoring effort on each coastal sectors    Motivation Compare the beach length monitored along 20 latitudinal sector of equal area.\n Data available: 10 individual coastline segments (shapefile format) located in different sub-directories\n Code structure: Part 01 - Create a function to open all dataset and merge them into one spatial layer.\nPart 02 - Create a new spatial layer with the 20 latitudinal sectors using the total extention of the monitored area.\nPart 03 - Deal with geometries intersection and calculate the total length of all segments within the each sector.\n Starting to code # Load libraries library(mapview) library(tidyverse) library(sf) Part 01 - Create a function Here, the objective is to create a function that can store in a list all spatial features of interest. The first step is to create an initial list with all the subdirectories containing the spatial features. In this case, all files have the suffix “linha.shp” which was used to set the list pattern:\n# create a list to be populated with all subdirectories containing the pattern \u0026quot;linha.shp\u0026quot; : ff \u0026lt;- as.list(list.files(path=\u0026quot;./\u0026quot;, pattern=\u0026quot;linha.shp$\u0026quot;, recursive=TRUE, full.names=TRUE)) Now we have a list with the individual directory for each of the 10 spatial features that can be imported to the R environment with the following fuction:\n## Function to open the shps in subdirectories open_shp \u0026lt;- function(ff){ linha \u0026lt;- st_read(ff[i]) linha } Loop the function over the list of subdirectories to return a final list with all spatial features:\n## A looping creating a list with all shapefiles linhas = list() for (i in 1:length(ff)) { linhas[[i]] \u0026lt;- open_shp(ff) } Finish this step merging all line segments into one feature and setting the right CRS and geometry column\n# Merge all monitoring lines in one shapefile merged.lines \u0026lt;- linhas %\u0026gt;% do.call(rbind, .) merged.lines \u0026lt;-do.call(rbind,lapply(1:nrow(merged.lines),function(i){st_cast(merged.lines[i,],\u0026quot;LINESTRING\u0026quot;)}))  Part 02 - Create 20 coastal sectors There is no spatial feature with the coastal sectors so this needs to be created. In this case, the whole monitored region needs to be divided in 20 sectors of same area, so the first step here is to find the latitudinal and longitudinal extention for these sectors:\n ## Find the latitudinal (m) and longitudinal (n) extention: n\u0026lt;-diff(st_bbox(merged.lines)[c(2, 4)])/20 ## calculate the total latitude extension and divide per 20 (sectors) ## CHANGE THE NUMBER HERE IF YOU WANT A MORE REFINED ANALYSIS!! m\u0026lt;-diff(st_bbox(merged.lines)[c(1, 3)]) ## calculate the total longitudinal area monitored Create the 20 coastal sectors by dividing the total area monitored and m and n as parameters\n## create 20 latitudinal sectors based on merged.lines extend sectors\u0026lt;-st_as_sf(st_make_grid(st_combine(merged.lines), cellsize = c(m,n))) sectors$id \u0026lt;- 1:nrow(sectors) ## create an identifier for each sector sectors \u0026lt;- sectors %\u0026gt;% st_cast(\u0026quot;MULTIPOLYGON\u0026quot;) ## define sectors as a multipolygon feature ## create a multiline feature based on \u0026quot;sectors\u0026quot; id limits: sectors_lines \u0026lt;- st_cast(sectors, \u0026quot;MULTILINESTRING\u0026quot;, group_or_split = FALSE)  Part 03 - Fix geometries intersection and calculate the monitoring effort on each coastal sectors Some of the monitored coastline segments intersect more than one coastal sector, and this fact can cause confusion to the analysis. In order to fix it, this segments must be indentified and split using the sector intersection.\nFirst thing to do is check for unvalid segments:\n# Check if there is any invalid geometry count(filter(merged.lines, compriment == 0)) ## the variable \u0026quot;compriment\u0026quot; correspond to the segment lenght in ## meters. If this value is equal to 0 this means that the geometry ## can be removed from the analysis ## Simple feature collection with 1 feature and 1 field (with 1 geometry empty) ## geometry type: LINESTRING ## dimension: XY ## bbox: xmin: NA ymin: NA xmax: NA ymax: NA ## proj4string: +proj=longlat +ellps=GRS80 +no_defs ## # A tibble: 1 x 2 ## n geometry ## \u0026lt;int\u0026gt; \u0026lt;LINESTRING [°]\u0026gt; ## 1 48 EMPTY Knowing that there are 48 unvalid segments, they will need to be filtered out from the analysis. To perform the intersection analysis we will need to transform Simple Features to Spatial Lines DataFrames with the function as_Spatial in the sf. With this transformation the function gIntersection in the rgeos can be used to identify the intersections, and then finally transform it back to a Simple Features to perform a spatial join with with the feature grid, importing the “Id” value for each segment.\nlibrary(rgeos) gridS \u0026lt;- sf:::as_Spatial(st_transform(sectors, 5641)) lineS \u0026lt;- sf:::as_Spatial(st_transform(filter(merged.lines, compriment != 0), 5641)) clipLine \u0026lt;- gIntersection(lineS, gridS, byid = TRUE) clipLine \u0026lt;- clipLine %\u0026gt;% st_as_sf() %\u0026gt;% st_join(left = FALSE, (st_as_sf(gridS))[\u0026quot;id\u0026quot;]) # join points With the new summarized feature it is possible to calculate the individual lenght of each new segment (without intersection between different latitudinal sectors) summarizing the total length per sector which will populate a new a column named “tot_monitored length” in the initial sector feature.\n## Calculate individual segment lengths for the new summarized feature clipLine$length \u0026lt;- as.numeric(st_length(clipLine))/1000 ## Add the total monitored length for each sector sector_monit_length \u0026lt;- clipLine %\u0026gt;% group_by(id) %\u0026gt;% summarise(tot_monitored_lenght = sum(length)) sectors\u0026lt;-merge(sectors, st_drop_geometry(sector_monit_length), by = \u0026quot;id\u0026quot;,all.x=TRUE) ## update the \u0026quot;sector\u0026quot; layer Visualise the result:\n## Check the five sectors with the highest monitoring effort: head(sectors[order(sectors$tot_monitored_lenght, decreasing = TRUE),]) ## Simple feature collection with 6 features and 2 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -48.76622 ymin: -26.6892 xmax: -44.78347 ymax: -23.3344 ## proj4string: +proj=longlat +ellps=GRS80 +no_defs ## id tot_monitored_lenght geometry ## 19 19 95.90087 MULTIPOLYGON (((-48.76622 -... ## 15 15 75.79817 MULTIPOLYGON (((-48.76622 -... ## 18 18 67.32648 MULTIPOLYGON (((-48.76622 -... ## 8 8 60.79107 MULTIPOLYGON (((-48.76622 -... ## 20 20 57.19828 MULTIPOLYGON (((-48.76622 -... ## 11 11 55.33324 MULTIPOLYGON (((-48.76622 -... ## Check the five sectors with the lowest monitoring effort: head(sectors[order(sectors$tot_monitored_lenght, decreasing = FALSE),]) ## Simple feature collection with 6 features and 2 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -48.76622 ymin: -28.23757 xmax: -44.78347 ymax: -24.36664 ## proj4string: +proj=longlat +ellps=GRS80 +no_defs ## id tot_monitored_lenght geometry ## 5 5 13.69308 MULTIPOLYGON (((-48.76622 -... ## 13 13 18.32505 MULTIPOLYGON (((-48.76622 -... ## 2 2 23.05482 MULTIPOLYGON (((-48.76622 -... ## 16 16 24.33563 MULTIPOLYGON (((-48.76622 -... ## 3 3 24.76599 MULTIPOLYGON (((-48.76622 -... ## 4 4 29.84013 MULTIPOLYGON (((-48.76622 -... Finally, we can spatially visualise the difference between each latitudinal sectors with the ones with less monitoiring efforts represented in red and the ones with more effots represented in green:\nlibrary(leaflet) bins \u0026lt;- c(0, 10, 20, 30, 50, 70, 100, Inf) pal \u0026lt;- colorBin(\u0026quot;RdYlGn\u0026quot;, domain = sectors$tot_monitored_lenght, bins = bins) leaflet(sf:::as_Spatial(sectors)) %\u0026gt;% addTiles() %\u0026gt;% addPolygons(color = \u0026quot;#444444\u0026quot;, weight = 1, smoothFactor = 0.5, opacity = 1.0, fillOpacity = 0.5, fillColor = ~pal(tot_monitored_lenght), highlightOptions = highlightOptions(color = \u0026quot;white\u0026quot;, weight = 2, bringToFront = TRUE), popup = ~tot_monitored_lenght )  {\"x\":{\"options\":{\"crs\":{\"crsClass\":\"L.CRS.EPSG3857\",\"code\":null,\"proj4def\":null,\"projectedBounds\":null,\"options\":{}}},\"calls\":[{\"method\":\"addTiles\",\"args\":[\"//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\",null,null,{\"minZoom\":0,\"maxZoom\":18,\"tileSize\":256,\"subdomains\":\"abc\",\"errorTileUrl\":\"\",\"tms\":false,\"noWrap\":false,\"zoomOffset\":0,\"zoomReverse\":false,\"opacity\":1,\"zIndex\":1,\"detectRetina\":false,\"attribution\":\"\u0026copy; OpenStreetMap contributors, CC-BY-SA\"}]},{\"method\":\"addPolygons\",\"args\":[[[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-28.495636824,-28.23757476575,-28.23757476575,-28.495636824,-28.495636824]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-28.23757476575,-27.9795127075,-27.9795127075,-28.23757476575,-28.23757476575]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-27.9795127075,-27.72145064925,-27.72145064925,-27.9795127075,-27.9795127075]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-27.72145064925,-27.463388591,-27.463388591,-27.72145064925,-27.72145064925]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-27.463388591,-27.20532653275,-27.20532653275,-27.463388591,-27.463388591]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-27.20532653275,-26.9472644745,-26.9472644745,-27.20532653275,-27.20532653275]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-26.9472644745,-26.68920241625,-26.68920241625,-26.9472644745,-26.9472644745]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-26.68920241625,-26.431140358,-26.431140358,-26.68920241625,-26.68920241625]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-26.431140358,-26.17307829975,-26.17307829975,-26.431140358,-26.431140358]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-26.17307829975,-25.9150162415,-25.9150162415,-26.17307829975,-26.17307829975]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-25.9150162415,-25.65695418325,-25.65695418325,-25.9150162415,-25.9150162415]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-25.65695418325,-25.398892125,-25.398892125,-25.65695418325,-25.65695418325]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-25.398892125,-25.1408300667499,-25.1408300667499,-25.398892125,-25.398892125]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-25.1408300667499,-24.8827680084999,-24.8827680084999,-25.1408300667499,-25.1408300667499]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-24.8827680084999,-24.6247059502499,-24.6247059502499,-24.8827680084999,-24.8827680084999]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-24.6247059502499,-24.3666438919999,-24.3666438919999,-24.6247059502499,-24.6247059502499]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-24.3666438919999,-24.1085818337499,-24.1085818337499,-24.3666438919999,-24.3666438919999]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-24.1085818337499,-23.8505197754999,-23.8505197754999,-24.1085818337499,-24.1085818337499]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-23.8505197754999,-23.5924577172499,-23.5924577172499,-23.8505197754999,-23.8505197754999]}]],[[{\"lng\":[-48.7662226649999,-48.7662226649999,-44.783474665,-44.783474665,-48.7662226649999],\"lat\":[-23.5924577172499,-23.3343956589999,-23.3343956589999,-23.5924577172499,-23.5924577172499]}]]],null,null,{\"interactive\":true,\"className\":\"\",\"stroke\":true,\"color\":\"#444444\",\"weight\":1,\"opacity\":1,\"fill\":true,\"fillColor\":[\"#FFFFBF\",\"#FEE08B\",\"#FEE08B\",\"#FEE08B\",\"#FC8D59\",\"#FFFFBF\",\"#FFFFBF\",\"#D9EF8B\",\"#D9EF8B\",\"#FFFFBF\",\"#D9EF8B\",\"#FFFFBF\",\"#FC8D59\",\"#FFFFBF\",\"#91CF60\",\"#FEE08B\",\"#FFFFBF\",\"#D9EF8B\",\"#91CF60\",\"#D9EF8B\"],\"fillOpacity\":0.5,\"smoothFactor\":0.5,\"noClip\":false},[35.8184353617669,23.0548167133741,24.7659886378299,29.8401270105745,13.6930840988839,30.5516372036213,36.7594831582133,60.7910667641981,50.0842901975882,36.9351111597452,55.3332414110109,38.1979140008277,18.3250478238633,30.8284978709684,75.7981702017037,24.3356256501222,47.2113847758834,67.3264811059651,95.9008672690657,57.198284556616],null,null,{\"interactive\":false,\"permanent\":false,\"direction\":\"auto\",\"opacity\":1,\"offset\":[0,0],\"textsize\":\"10px\",\"textOnly\":false,\"className\":\"\",\"sticky\":true},{\"color\":\"white\",\"weight\":2,\"bringToFront\":true}]}],\"limits\":{\"lat\":[-28.495636824,-23.3343956589999],\"lng\":[-48.7662226649999,-44.783474665]}},\"evals\":[],\"jsHooks\":[]} #m %\u0026gt;% addLegend(pal = pal, values = ~tot_monitored_lenght, opacity = 0.7, title = NULL, # position = \u0026quot;bottomright\u0026quot;) With the end of this code we have a spatial visualisation that tells the sectors with a higher (red polygons) and lower (light yellow polygons) monitoring effort. This result can be saved in a new shapefile and opened in any other geospatial software:\n# st_write(sectors,\u0026quot;./sectors.shp\u0026quot;) ## saving the sectors as a .shp   ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"71f90f2bf72f04b572fb18c056bf9a9e","permalink":"/post/2020-05-06-blog-functionpmp/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/post/2020-05-06-blog-functionpmp/","section":"post","summary":"How to compare monitoring effort between latitudinal sectors","tags":["coastal monitoring","how to","biological data"],"title":"How to Compare Monitoring Effort Between Latitudinal Sectors","type":"post"},{"authors":null,"categories":null,"content":"This project is a framework for a beach litter monitoring, based on free and open-source software (FOSS), which allows adjustments for any sampling design. The framework was developed by means of a GIS-project (QGIS), a GIS-collector (QField), and an R code, allowing further adjustments according to the area to be surveyed, and research questions. All facilities are FOSS, not implying any costs. The aim is to improve data collection, accessibility, and interoperability, and to help to fill the current existing gap between fieldwork and data analysis, preventing typos and allowing better data processing.\nImage 1. The mobile-app QField in the fieldwork. (a) Record the item; (b–c) fill the attributes.\nTherefore, less than an hour is expected from ending the fieldwork to the resulting up-to-date products. Results obtained from the open-source geospatial framework application produces baseline information on beach litter issues, such as amounts, sources, spatial and temporal patterns.\nImage 2. Summary of graphical and descriptive results and the questions that these individual products respond. Colours are related to different polluting-activities, capital letters (A, B, C) represents different sites, and lower case letters (a, b) different beach areas.\nThe adoption of the framework can facilitate the data collection by local and regional councils as it dispense any financial investments, and the results obtained from it can be applied to base management strategies. For researchers, it produces spatialized data from each item in tidy forms.\nImage 3. Coloured cells indicate the steps to be run in the code, depending on the users purpose (reproduce results; first input of data; or, second data input onwards).\nThis project was submitted to the Environmental Monitoring and Assessment Journal (Manuscript status: in review) and the full code is available here\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"74fb9a2f325f996c412e1bf151e8b459","permalink":"/project/litter/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/litter/","section":"project","summary":"An open-source geospatial framework for beach litter monitoring","tags":["beach litter","gis","open data"],"title":"FOSS4G for Beach Litter Monitoring","type":"project"},{"authors":null,"categories":null,"content":"The coastline is the limit between the terrestrial and the maritime environment reflecting in its shape the interaction of continental and marine processes, presenting it as an interesting feature for coastal characterization. In this sense, this current project analyses by quantitative descriptors the morphological complexity of the south-southest brazilian coastline. Three different techniques are used to reach this objective, two of them are based in fractal theory and one in angular variation. The whole methodology is based in a reproducible R-code using public databases. In the characterization using fractal methods, the complexity of four coastline compartments of the study are measured by the fractal dimension (D). The adjustment of the fractal curve (R2) and the type of data used indicates that the step-divisor is the best method in this case. In a second moment of this project, the Angular Measurement Technique (AMT) is applied to the coastline without a previous compartmentalization, reaching to classify coastline segments in complexity classes. Nine different scale lengths (S) we considered in an hierarchic cluster indicating that the strudy area can be classified in four different complexity groups. Segments classified by Group 01 have low complexity being associated to straight coastline, Group 02 has an intermediate complexity while Group 03 and 04 have a higher complexity being segments of Group 04 normally associated to headlands and bays. Additionally,the relationship between this morphological classification is compared to the variability four coastal descriptors, the lithological diversity, the concentration of structural faults and the submerged and emerged slope.\nImage 1. Methodological framework with a general visualisation of the input data in the first row (lithology, geological faults and bathimetric and topographic data, respectively), and on the second row is a sampled of the scheme used to obtain the four coastal descriptor for each costal segment (Shannon index, concentration of faults, submerged and emerged slope, respectively).\nPrincipal Component Analysis (PCA) shows that the lithological diversity and the concentration of faults control the coastline morphology in the scale evaluated by this study, possibly reflecting the influence of the Serra do Mar proximity in some segments. However, the smoothed curve of each complexity group obtained by the generalized additive model (GAM) from the individual bathymetric and altimetric profiles shows a variation between the pattern observed for each group, indicating a relation with the morphological expression of the coastline.\nImage 2. Principal Component Analysis for the four complexity groups (represented by points) in relations to the four coastal descriptors (represented by arrows being translated from portuguese to english as follow: Decliv. Sub = Submerged Slope; Decliv. Emersa = Emerged Slope; Div. Geo = Shannon Index; Conc. Falhas = Fault Concentration). This analysis highlights the geological diversity on controlling the morphological expression of the coastline in mesoscale\nThe full dataset and the final code are freely available in my github\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"Methodological process of my master thesis divided in two chapters.","tags":["coastal oceanography","gis","open data"],"title":"Measuring the coastal complexity","type":"project"},{"authors":["Jessica Leiria Schattschneider","Nicholas W. Daudt","Mariana P. S. Mattos","Jarbas Bonetti","Nelson Rangel-Buitrago"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Environmental Monitoring and Assessment (2019)","tags":["Beach litter, FOSS4G"],"title":"An open-source geospatial framework for beach litter monitoring","type":"publication"},{"authors":["Jessica Leiria Schattschneider"],"categories":["Python"],"content":" Motivation  Work with Covid-19 dataset Compare the curve from my home country Brazil (no social distance and insufficient testing - https://www.theguardian.com/world/2020/may/06/brazil-coronavirus-deaths-covid-19-bolsonaro) and New Zealand (four weeks of lockdown and with a recognized elimination strategy - https://edition.cnn.com/2020/04/28/asia/new-zealand-coronavirus-outbreak-elimination-intl-hnk/index.html)  Source: To structure the code below two main references were used:\n https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/ https://opensource.com/article/20/4/python-data-covid-19  Coding: Import libraries\nimport pycountry import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns  Import the dataset\nFind additional information about the dataset here: https://github.com/datasets/covid-19\nURL_DATASET = r'https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv' df1 = pd.read_csv(URL_DATASET)  Select only the data needed and get it in the right shape to the analysis\n## Filtering and Wrangling df1 = df1.filter([\u0026quot;Country\u0026quot;, \u0026quot;Date\u0026quot;, \u0026quot;Confirmed\u0026quot;]) ## Select only the columns of interest bra_nz = df1.loc[df1[\u0026quot;Country\u0026quot;].isin(['Brazil','New Zealand'])] ## Select the countries to be analysed bra_nz[\u0026quot;Date\u0026quot;] = pd.to_datetime(bra_nz[\u0026quot;Date\u0026quot;]) ## Set the right format to Date column bra_nz=bra_nz.pivot(index='Date', columns='Country', values='Confirmed') ## Reshape the dataset ## Define columns data_columns = ['Brazil', 'New Zealand']  Perform a log transformation on the number of confirmed cases and set a rolling window of seven days\n## And index retrieveing month ## and rolling bra_nz_7d = np.log(bra_nz[data_columns]).rolling(7, center=True).mean() ## The logarithmic scale improves the rate ## change analysis and the rolling window ## smooths the graph  Plot the curves and a red vertical line indicating the first day of New Zealand lockdown\n# Plot 7-day rolling mean time series for the confirmed cases of Brazil and New Zealand: fig, ax = plt.subplots() ax.plot(bra_nz_7d['Brazil'], linewidth=2, label='7-d Rolling Brazil', color='green') ax.plot(bra_nz_7d['New Zealand'], linewidth=2, label='7-d Rolling New Zealand', color='blue') ax.axvline(pd.to_datetime('2020-03-26'), color='r', linestyle='--', lw=2) # Set x-ticks to yearly interval and add legend and labels ax.legend() ax.set_ylabel('Confirmed Cases') ax.set_title('Comparing Covid-19 Trends- Brazil and New Zealand');   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"40c8342e3e21678299976cffe731f7a9","permalink":"/post/covid/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/covid/","section":"post","summary":"Basic code to compare Covid-19 curves","tags":["data wrangling","covid","pandas"],"title":"How to Compare Covid-19 Curves in Python","type":"post"},{"authors":["Jessica Leiria Schattschneider","Jarbas Bonetti"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1a269fcbe32264eb00b718ceebc09c19","permalink":"/publication/complexity/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/complexity/","section":"publication","summary":"Revista Brasileira de Geomorfologia (2020)","tags":["Beach litter, FOSS4G"],"title":"Quantitative Caracterization of the Morphometric Complexity of South-Southest Brazilian Coastline using Fractal Methods","type":"publication"}]